# Natural Language Processing

## 1. Neural Machine Translation by Jointly Learning to Align and Translate [[paper](https://arxiv.org/abs/1409.0473)][[code](https://github.com/yubin1219/NLP/blob/main/Assignment1/Assign1.py)]
## 2. Attention is All You Need [[paper](https://arxiv.org/abs/1706.03762)][[code](https://github.com/yubin1219/NLP/blob/main/Assignment2/Assignment2_code.py)]
## 3. XLNet: Generalized Autoregressive Pretraining for Language Understanding [[paper](https://arxiv.org/abs/1906.08237)][[code](https://github.com/yubin1219/NLP/tree/main/Assignment3)]
## 4. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators [[paper](https://arxiv.org/abs/2003.10555)][[code](https://github.com/yubin1219/NLP/tree/main/Assignment4)]
## 5. DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation [[paper](https://arxiv.org/abs/1911.00536)][[code](https://github.com/yubin1219/NLP/tree/main/Assignment5)]
